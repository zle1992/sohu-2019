{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "import keras.preprocessing.text as T\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dropout,\\\n",
    "                         TimeDistributed, Concatenate, Dense, GRU, Conv1D,\\\n",
    "                         LeakyReLU,concatenate,GlobalMaxPool1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from CrfLayer import CRF\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "tfconfig = tf.ConfigProto()\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=tfconfig)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def word2id(texts,MAXLEN):\n",
    "\n",
    "\n",
    "  tokenizer = Tokenizer(num_words=None,) # 分词MAX_NB_WORDS\n",
    "  tokenizer.fit_on_texts(texts)\n",
    "  X_train_word_ids = tokenizer.texts_to_sequences(texts) #受num_words影响\n",
    "  x_data=pad_sequences(X_train_word_ids,maxlen=MAXLEN,truncating='post',padding='post',value=0)\n",
    "\n",
    "  n_vocab_char = len(tokenizer.index_word)+1\n",
    " \n",
    "  return x_data,n_vocab_char\n",
    "\n",
    "\n",
    "def text2id(x,col='content'):\n",
    "    content =x[col]\n",
    "    content_label =len(content) *[1]\n",
    "    content_label = np.array(content_label)\n",
    "    try:\n",
    "       \n",
    "        pattern =x['entity'].replace(' ','|')\n",
    "        it = re.finditer(pattern,content) \n",
    "        for match in it: \n",
    "          start,end = match.span()\n",
    "          if(start==end):\n",
    "              continue\n",
    "          content_label[start]=2\n",
    "          content_label[(start+1):end]=3\n",
    "    except:\n",
    "        pass\n",
    "    return list(content_label)\n",
    "\n",
    "\n",
    "def decoder(text_ids,texts):\n",
    "  final_res =[]\n",
    "  for i in range(len(text_ids)):\n",
    "      text = texts[i]\n",
    "      text_id =text_ids[i]\n",
    "      res = ''\n",
    "      for j in range(len(text_id)):\n",
    "          if(text_id[j]==1 or text_id[j]==0):\n",
    "              pass\n",
    "          else:\n",
    "              if(text_id[j])==2:\n",
    "                  res =res+' '+text[j]\n",
    "              else:\n",
    "                  res=res+text[j]\n",
    "      final_res.append(res)\n",
    "  return final_res\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "def post(x):\n",
    "    #格式处理：c\n",
    "    x = np.array(x).flatten().tolist()\n",
    "    x=' '.join(x)\n",
    "    x = x.split() \n",
    "    #过滤\n",
    "\n",
    "    return[i[0] for i in  Counter(x).most_common(3)]\n",
    "\n",
    "def postposs(df):\n",
    "  '''\n",
    "\n",
    "  聚合结果\n",
    "  '''\n",
    "\n",
    "  df.fillna(' ',inplace=False)\n",
    "  print(list(df))\n",
    "  feat_agg = ['entity_pred','entity',]\n",
    "  gg = df.groupby(['newsId'])\n",
    "  df_agg = gg[feat_agg[0]].apply(lambda x:' '.join(x)).reset_index()\n",
    "  for f in feat_agg:\n",
    "      df_agg[f] = gg[f].apply(list).reset_index()[f]\n",
    "  df_agg['entity']= df_agg['entity'].map(lambda x:x[0])\n",
    "\n",
    "  print(list(df_agg))\n",
    "\n",
    "  return df_agg \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path='../data/coreEntityEmotion_train.txt.agg.pick'\n",
    "df_new=pd.read_pickle(out_path)\n",
    "#agg新闻太长把句子分开。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>texts</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>sia智慧工厂展，誉洋以“智”取胜。第十七届上海国际工业自动化及机器人展与上海智能工厂展览会...</td>\n",
       "      <td>3d 工业 机器视觉</td>\n",
       "      <td>POS POS POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>业智能设备的研发、生产制造和服务，创新理念伴随企业不断成长。今天的誉洋已与中国多家企业达成合...</td>\n",
       "      <td>3d 工业 机器视觉</td>\n",
       "      <td>POS POS POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>大数据可视化应用领域探析。大数据之热度，已无需多言。业内众多关于大数据可视化应用领域的声音与...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>分布与运行态势情况。案例2：卫星分布运行可视化通过将宇宙空间内所有卫星的运行数据进行可视化展...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>和监测。应用领域三、数据统计分析可视化此领域是目前媒体大众提及最多的应用，可用于商业智能、政...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                                              texts      entity  \\\n",
       "0  4e36d02a  sia智慧工厂展，誉洋以“智”取胜。第十七届上海国际工业自动化及机器人展与上海智能工厂展览会...  3d 工业 机器视觉   \n",
       "1  4e36d02a  业智能设备的研发、生产制造和服务，创新理念伴随企业不断成长。今天的誉洋已与中国多家企业达成合...  3d 工业 机器视觉   \n",
       "2  cb8e8b79  大数据可视化应用领域探析。大数据之热度，已无需多言。业内众多关于大数据可视化应用领域的声音与...   数据 卫星 可视化   \n",
       "3  cb8e8b79  分布与运行态势情况。案例2：卫星分布运行可视化通过将宇宙空间内所有卫星的运行数据进行可视化展...   数据 卫星 可视化   \n",
       "4  cb8e8b79  和监测。应用领域三、数据统计分析可视化此领域是目前媒体大众提及最多的应用，可用于商业智能、政...   数据 卫星 可视化   \n",
       "\n",
       "       emotion  \n",
       "0  POS POS POS  \n",
       "1  POS POS POS  \n",
       "2  POS POS POS  \n",
       "3  POS POS POS  \n",
       "4  POS POS POS  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['labels']=df_new.apply(lambda x:text2id(x,col='texts'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>texts</th>\n",
       "      <th>entity</th>\n",
       "      <th>emotion</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>sia智慧工厂展，誉洋以“智”取胜。第十七届上海国际工业自动化及机器人展与上海智能工厂展览会...</td>\n",
       "      <td>3d 工业 机器视觉</td>\n",
       "      <td>POS POS POS</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4e36d02a</td>\n",
       "      <td>业智能设备的研发、生产制造和服务，创新理念伴随企业不断成长。今天的誉洋已与中国多家企业达成合...</td>\n",
       "      <td>3d 工业 机器视觉</td>\n",
       "      <td>POS POS POS</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>大数据可视化应用领域探析。大数据之热度，已无需多言。业内众多关于大数据可视化应用领域的声音与...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>分布与运行态势情况。案例2：卫星分布运行可视化通过将宇宙空间内所有卫星的运行数据进行可视化展...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb8e8b79</td>\n",
       "      <td>和监测。应用领域三、数据统计分析可视化此领域是目前媒体大众提及最多的应用，可用于商业智能、政...</td>\n",
       "      <td>数据 卫星 可视化</td>\n",
       "      <td>POS POS POS</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                                              texts      entity  \\\n",
       "0  4e36d02a  sia智慧工厂展，誉洋以“智”取胜。第十七届上海国际工业自动化及机器人展与上海智能工厂展览会...  3d 工业 机器视觉   \n",
       "1  4e36d02a  业智能设备的研发、生产制造和服务，创新理念伴随企业不断成长。今天的誉洋已与中国多家企业达成合...  3d 工业 机器视觉   \n",
       "2  cb8e8b79  大数据可视化应用领域探析。大数据之热度，已无需多言。业内众多关于大数据可视化应用领域的声音与...   数据 卫星 可视化   \n",
       "3  cb8e8b79  分布与运行态势情况。案例2：卫星分布运行可视化通过将宇宙空间内所有卫星的运行数据进行可视化展...   数据 卫星 可视化   \n",
       "4  cb8e8b79  和监测。应用领域三、数据统计分析可视化此领域是目前媒体大众提及最多的应用，可用于商业智能、政...   数据 卫星 可视化   \n",
       "\n",
       "       emotion                                             labels  \n",
       "0  POS POS POS  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  POS POS POS  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  POS POS POS  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  POS POS POS  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  POS POS POS  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=df_new['texts'].map(lambda x:list(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms={} \n",
    "parms['MAXLEN']=40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_id ,parms['n_vocab_char']= word2id(texts,parms['MAXLEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8273"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms['n_vocab_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45081, 40)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_id.shape\n",
    "#多少行多少个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-34c7ed6981b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'text_id' is not defined"
     ]
    }
   ],
   "source": [
    "text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_new['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_id=pad_sequences(labels,maxlen=parms['MAXLEN'],truncating='post',padding='post',value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_id shape (45081, 40)\n",
      "texts_id (45081, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new['labels']=df_new.apply(lambda x:text2id(x,col='texts'),axis=1)\n",
    "\n",
    "texts=df_new['texts'].map(lambda x:list(x)).values\n",
    "texts_id ,parms['n_vocab_char']= word2id(texts,parms['MAXLEN'])\n",
    "\n",
    "labels = df_new['labels'].values\n",
    "labels_id=pad_sequences(labels,maxlen=parms['MAXLEN'],truncating='post',padding='post',value=0)\n",
    "\n",
    "print('labels_id shape',labels_id.shape)\n",
    "print('texts_id',texts_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'数据 卫星 可视化'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.iloc[14].entity                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =df_new.iloc[14].texts      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "数据 卫星 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = '数据 卫星 可视化'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'数据传输等等。除此之外，对卫星回传的数据，卫星自身的状态，也有针对性的可视化分析和监测。应用领域三、数据统计分析可视化此领域是目前媒体大众提及最多的应用，可用于商业智能、政府决策、公众服务、市场营销等领域。1.商业智能可视化通过采集相关数据'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "content =s\n",
    "content_label =len(content) *[-1]\n",
    "content_label = np.array(content_label)\n",
    "\n",
    "\n",
    "pattern =e.replace(' ','|')\n",
    "it = re.finditer(pattern,content) \n",
    "for match in it: \n",
    "    start,end = match.span()\n",
    "    if(start==end):\n",
    "      continue\n",
    "    content_label[start]=2\n",
    "    content_label[(start+1):end]=3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(content_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_agg = ['emotion','entity',]\n",
    "gg = df_new.groupby(['newsId'])\n",
    "df_agg = gg[feat_agg[0]].apply(lambda x:' '.join(x)).reset_index()\n",
    "for f in feat_agg:\n",
    "    df_agg[f] = gg[f].apply(list).reset_index()[f]\n",
    "df_agg['entity']= df_agg['entity'].map(lambda x:x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postposs(df):\n",
    "  '''\n",
    "\n",
    "  聚合结果\n",
    "  '''\n",
    "\n",
    "  df.fillna(' ',inplace=False)\n",
    "  print(list(df))\n",
    "  feat_agg = ['entity_pred','entity']\n",
    "  gg = df.groupby(['newsId'])\n",
    "  df_agg = gg[feat_agg[0]].apply(lambda x:' '.join(x)).reset_index()\n",
    "  for f in feat_agg:\n",
    "      df_agg[f] = gg[f].apply(list).reset_index()[f]\n",
    "  df_agg['entity']= df_agg['entity'].map(lambda x:x[0])\n",
    "\n",
    "  print(list(df_agg))\n",
    "\n",
    "  return df_agg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post(x):\n",
    "    #格式处理：\n",
    "    x = np.array(x).flatten().tolist()\n",
    "    x=' '.join(x)\n",
    "    x = x.split() \n",
    "    #过滤\n",
    "\n",
    "    return[i[0] for i in  Counter(x).most_common(3)]\n",
    "#取出现次数最长的当预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['predict'] = df_agg['predict'].map(lambda x:post(x))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newsId</th>\n",
       "      <th>predict</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>613e366f</td>\n",
       "      <td>[[], ['黄伟栋']]</td>\n",
       "      <td>cier 春招 薪酬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6407142f</td>\n",
       "      <td>[[], ['增肥'], ['两块代']]</td>\n",
       "      <td>马思纯 新戏 减肥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>940b4eb1</td>\n",
       "      <td>[[], ['都挺好'], ['郭京飞']]</td>\n",
       "      <td>重男轻女 都挺好 原生家庭</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb26f088</td>\n",
       "      <td>[[], ['鹿晗'], ['民国']]</td>\n",
       "      <td>鹿晗 民国 表情包</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     newsId                 predict         entity\n",
       "0  613e366f           [[], ['黄伟栋']]     cier 春招 薪酬\n",
       "1  6407142f   [[], ['增肥'], ['两块代']]      马思纯 新戏 减肥\n",
       "2  940b4eb1  [[], ['都挺好'], ['郭京飞']]  重男轻女 都挺好 原生家庭\n",
       "3  cb26f088    [[], ['鹿晗'], ['民国']]      鹿晗 民国 表情包"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_score(real,predict):\n",
    "    for i in range(len(real)):\n",
    "        tp+=len(set())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
